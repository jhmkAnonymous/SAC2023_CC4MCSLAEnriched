{"cells":[{"cell_type":"code","execution_count":1,"id":"FOvNMxQdjQKi","metadata":{"id":"FOvNMxQdjQKi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668551157460,"user_tz":-60,"elapsed":30248,"user":{"displayName":"Jeremy MECHOUCHE","userId":"11311834437755446740"}},"outputId":"939216af-760b-4357-caea-b169666a24db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"22701961","metadata":{"id":"22701961"},"outputs":[],"source":["!pip install pm4py owlready2 pandas"]},{"cell_type":"markdown","source":["State Machine model definition"],"metadata":{"id":"JP45nrKFw6Bh"},"id":"JP45nrKFw6Bh"},{"cell_type":"code","source":["from collections import Counter\n","from copy import deepcopy\n","import time\n","import networkx as nx\n","class StateMachine(object):\n","    class state(object):\n","        def __init__(self, name, type, Resourcerequirements=None):\n","            self.__name = name\n","            self.__type = type\n","            self.__Resourcerequirements = set() if Resourcerequirements is None else Resourcerequirements\n","\n","        def __set_name(self, name):\n","            self.__name = name\n","\n","        def __get_name(self):\n","            return self.__name\n","\n","        def __set_type(self, type):\n","            self.__type = type\n","        \n","        def set_type(self, type):\n","            self.__type = type\n","\n","        def __get_type(self):\n","            return self.__type\n","\n","        def __get_out_transitions(self):\n","            return self.__out_transitions\n","\n","        def __get_in_transitions(self):\n","            return self.__in_transitions\n","\n","        def __get_Resourcerequirements(self):\n","            return self.__Resourcerequirements\n","\n","        def __repr__(self):\n","            return str(\"(\"+self.name+\", \"+ self.type +\", \"+ repr(self.Resourcerequirements) +\")\" )\n","\n","        def __str__(self):\n","            return self.__repr__()\n","\n","        def __eq__(self, other):\n","            # keep the ID for now in states\n","            return id(self) == id(other)\n","\n","        def __hash__(self):\n","            # keep the ID for now in states\n","            return id(self)\n","\n","        def __deepcopy__(self, memodict={}):\n","            if id(self) in memodict:\n","                return memodict[id(self)]\n","            new_state = StateMachine.state(self.name, Resourcerequirements=self.Resourcerequirements)\n","            memodict[id(self)] = new_state\n","            for transition in self.in_transitions:\n","                new_transition = deepcopy(transition, memo=memodict)\n","                new_state.in_transitions.add(new_transition)\n","            for transition in self.out_transitions:\n","                new_transition = deepcopy(transition, memo=memodict)\n","                new_state.out_transitions.add(new_transition)\n","            return new_state\n","\n","        name = property(__get_name, __set_name)\n","        type = property(__get_type, __set_type)\n","        Resourcerequirements = property(__get_Resourcerequirements)\n","\n","    class transition(object):\n","        def __init__(self, name, source, target, events=None, actions=None):\n","            self.__name = name\n","            self.__source = source\n","            self.__target = target\n","            self.__actions = set() if actions is None else actions\n","            self.__events = set() if events is None else events\n","\n","        def __get_name(self):\n","            return self.__name\n","\n","        def __get_source(self):\n","            return self.__source\n","        \n","        def __get_actions(self):\n","            return self.__actions\n","\n","        def __get_events(self):\n","            return self.__events\n","\n","        def __get_target(self):\n","            return self.__target\n","\n","        def __get_properties(self):\n","            return self.__properties\n","\n","        def __repr__(self):\n","            name_rep = repr(self.name)\n","            source_rep = repr(self.source)\n","            target_rep = repr(self.target)\n","            events_rep = repr(self.events)\n","            actions_rep = repr(self.actions)\n","            return \"(\"+name_rep+\":\"+source_rep+\"->\"+target_rep+\",\"+events_rep+\",\"+actions_rep+\")\"\n","\n","        def __str__(self):\n","            return self.__repr__()\n","\n","        def __hash__(self):\n","            return id(self)\n","\n","        def __eq__(self, other):\n","            return self.source == other.source and self.target == other.target\n","\n","        def __deepcopy__(self, memodict={}):\n","            if id(self) in memodict:\n","                return memodict[id(self)]\n","            new_source = memodict[id(self.source)] if id(self.source) in memodict else deepcopy(self.source,\n","                                                                                                memo=memodict)\n","            new_target = memodict[id(self.target)] if id(self.target) in memodict else deepcopy(self.target,\n","                                                                                                memo=memodict)\n","            memodict[id(self.source)] = new_source\n","            memodict[id(self.target)] = new_target\n","            new_transition = StateMachine.transition(new_source, new_target, weight=self.weight, properties=self.properties)\n","            memodict[id(self)] = new_transition\n","            return new_transition\n","\n","        name = property(__get_name)\n","        source = property(__get_source)\n","        target = property(__get_target)\n","        events = property(__get_events)\n","        actions = property(__get_actions)\n","        properties = property(__get_properties)\n","\n","    class event(object):\n","        def __init__(self, id, type, predicate):\n","            self.__id = id\n","            self.__type = type\n","            self.__predicate = predicate\n","        \n","        def __get_id(self):\n","            return self.__id\n","        \n","        def __get_type(self):\n","            return self.__type\n","        \n","        def __get_predicate(self):\n","            return self.__predicate\n","        \n","        id = property(__get_id)\n","        type = property(__get_type)\n","        predicate = property(__get_predicate)\n","\n","    class action(object):\n","        def __init__(self, id, type, attributes):\n","            self.__id = id\n","            self.__type = type\n","            self.__attributes = attributes\n","        \n","        def __get_id(self):\n","            return self.__id\n","        \n","        def __get_type(self):\n","            return self.__type\n","\n","    def add_state(self, new_state):\n","        self.states.add(new_state)\n","        self.graph.add_node(new_state.name)\n","\n","    def add_transition(self, new_transition):\n","        self.transitions.add(new_transition)\n","        self.graph.add_edge(new_transition.source, new_transition.target)\n","\n","    def __init__(self, name=None, states=None, transitions=None):\n","        self.__name = \"\" if name is None else name\n","        self.__states = set() if states is None else states\n","        self.__transitions = set() if transitions is None else transitions\n","        self.__graph = nx.DiGraph()\n","\n","    def __get_name(self):\n","        return self.__name\n","\n","    def __set_name(self, name):\n","        self.__name = name\n","\n","    def __get_states(self):\n","        return self.__states\n","\n","    def __get_transitions(self):\n","        return self.__transitions\n","\n","    def __get_graph(self):\n","        return self.__graph\n","\n","    def __hash__(self):\n","        ret = 0\n","        for p in self.states:\n","            ret += hash(p)\n","            ret = ret % 479001599\n","        for t in self.transitions:\n","            ret += hash(t)\n","            ret = ret % 479001599\n","        return ret\n","\n","    def __eq__(self, other):\n","        # for the Petri net equality keep the ID for now\n","        return id(self) == id(other)\n","\n","    def __deepcopy__(self, memodict={}):\n","        from pm4py.objects.petri_net.utils.petri_utils import add_transition_from_to\n","        this_copy = StateMachine(self.name)\n","        memodict[id(self)] = this_copy\n","        for state in self.states:\n","            state_copy = StateMachine.state(state.name, properties=state.properties)\n","            this_copy.states.add(state_copy)\n","            memodict[id(state)] = state_copy\n","        for trans in self.transitions:\n","            trans_copy = StateMachine.Transition(trans.name, trans.label, properties=trans.properties)\n","            this_copy.transitions.add(trans_copy)\n","            memodict[id(trans)] = trans_copy\n","        for transition in self.transitions:\n","            add_transition_from_to(memodict[id(transition.source)], memodict[id(transition.target)], this_copy, weight=transition.weight)\n","        return this_copy\n","\n","    def __repr__(self):\n","        ret = [\"states: [\"]\n","        states_rep = []\n","        for state in self.states:\n","            states_rep.append(repr(state))\n","        states_rep.sort()\n","        ret.append(\" \" + \", \".join(states_rep) + \" \")\n","        ret.append(\"]\\ntransitions: [\")\n","        trans_rep = []\n","        for trans in self.transitions:\n","            trans_rep.append(repr(trans))\n","        trans_rep.sort()\n","        ret.append(\" \" + \", \".join(trans_rep) + \" \")\n","        ret.append(\"]\")\n","        return \"\".join(ret)\n","\n","    def __str__(self):\n","        return self.__repr__()\n","\n","    name = property(__get_name, __set_name)\n","    states = property(__get_states)\n","    transitions = property(__get_transitions)\n","    graph = nx.DiGraph()\n","\n","\n","SM_defined = StateMachine(name='UI')\n","SM_defined.states.add(\n","    StateMachine.state(\n","        name = 'S1',\n","        type = 'isInitial',\n","        Resourcerequirements = {\n","            'replicas': 1\n","        }\n","    ))\n","SM_defined.states.add(\n","    StateMachine.state(\n","        name = 'S2',\n","        type = 'isNormal',\n","        Resourcerequirements = {\n","            'replicas': 2\n","        }\n","    ))\n","SM_defined.states.add(\n","    StateMachine.state(\n","        name = 'S3',\n","        type = 'isNormal',\n","        Resourcerequirements = {\n","            'replicas': 4\n","        }\n","    ))\n","SM_defined.states.add(\n","    StateMachine.state(\n","        name = 'S4',\n","        type = 'isFinal',\n","        Resourcerequirements = {\n","            'replicas': 0\n","        }\n","    ))\n","SM_defined.transitions.add(\n","    StateMachine.transition(\n","    'T1', 'S1', 'S4', \n","        events={\n","            'id': \"E1\",\n","            'type': \"TemporalEvent\",\n","            'predicate': \"2021-08-04 15:00:00\"}, \n","        actions={\n","            'id': \"A1\",\n","            'type': \"Scale-in\",\n","            'attributes': {\n","                'resource': \"UI\",\n","                'replicas': \"1\"}\n","        })\n","    )\n","SM_defined.transitions.add(\n","    StateMachine.transition(\n","    'T2', 'S2', 'S4', \n","        events={\n","            'id': \"E1\",\n","            'type': \"TemporalEvent\",\n","            'predicate': \"2021-08-04 15:00:00\"}, \n","        actions={\n","            'id': \"A2\",\n","            'type': \"Scale-in\",\n","            'attributes': {\n","                'resource': \"UI\",\n","                'replicas': \"2\"}\n","        })\n","    )\n","SM_defined.transitions.add(\n","    StateMachine.transition(\n","    'T3', 'S3', 'S4', \n","        events={\n","            'id': \"E1\",\n","            'type': \"TemporalEvent\",\n","            'predicate': \"2021-08-04 15:00:00\"}, \n","        actions={\n","            'id': \"A2\",\n","            'type': \"Scale-in\",\n","            'attributes': {\n","                'resource': \"UI\",\n","                'replicas': \"2\"}\n","        })\n","    )\n","SM_defined.transitions.add(\n","    StateMachine.transition(\n","    'T4', 'S1', 'S2', \n","        events={\n","            'id': \"E3\",\n","            'type': \"ResourceRelatedEvent\",\n","            'predicate': {\n","                'metric': \"cpuusage\",\n","                'operator': \">=\",\n","                'refValue': 80,\n","                'time': \"60s\"\n","            }}, \n","        actions={\n","            'id': \"A3\",\n","            'type': \"Scale-out\",\n","            'attributes': {\n","                'resource': \"UI\",\n","                'replicas': \"1\"}\n","        })\n","    )\n","SM_defined.transitions.add(\n","    StateMachine.transition(\n","    'T5', 'S2', 'S3', \n","        events={\n","            'id': \"E2\",\n","            'type': \"ResourceRelatedEvent\",\n","            'predicate': {\n","                'metric': \"cpuusage\",\n","                'operator': \"<=\",\n","                'refValue': 20,\n","                'time': \"60s\"\n","            }}, \n","        actions={\n","            'id': \"A3\",\n","            'type': \"Scale-out\",\n","            'attributes': {\n","                'resource': \"UI\",\n","                'replicas': \"1\"}\n","        })\n","    )\n","SM_defined.transitions.add(\n","    StateMachine.transition(\n","    'T6', 'S3', 'S2', \n","        events={\n","            'id': \"E2\",\n","            'type': \"ResourceRelatedEvent\",\n","            'predicate': {\n","                'metric': \"cpuusage\",\n","                'operator': \"<=\",\n","                'refValue': 20,\n","                'time': \"60s\"\n","            }}, \n","        actions={\n","            'id': \"A4\",\n","            'type': \"Scale-in\",\n","            'attributes': {\n","                'resource': \"UI\",\n","                'replicas': \"1\"}\n","        })\n","    )\n","SM_defined.transitions.add(\n","    StateMachine.transition(\n","    'T7', 'S2', 'S1', \n","        events={\n","            'id': \"E2\",\n","            'type': \"ResourceRelatedEvent\",\n","            'predicate': {\n","                'metric': \"cpuusage\",\n","                'operator': \"<=\",\n","                'refValue': 20,\n","                'time': \"60s\"\n","            }}, \n","        actions={\n","            'id': \"A4\",\n","            'type': \"Scale-in\",\n","            'attributes': {\n","                'resource': \"UI\",\n","                'replicas': \"1\"}\n","        })\n","    )"],"metadata":{"id":"d3sUFk0Aw3gH","executionInfo":{"status":"ok","timestamp":1668551189954,"user_tz":-60,"elapsed":642,"user":{"displayName":"Jeremy MECHOUCHE","userId":"11311834437755446740"}}},"id":"d3sUFk0Aw3gH","execution_count":3,"outputs":[]},{"cell_type":"markdown","id":"35e2e563","metadata":{"id":"35e2e563"},"source":["<h1>Experiments Leveraging Conformance Checking Techniques for Multi-Cloud SLA Compliance </h1>"]},{"cell_type":"markdown","id":"7e6e2315","metadata":{"id":"7e6e2315"},"source":["The main objective of this notebook is to present the implementation part of the paper submited to SAC 2023. This implementation is decomposed in two steps: Log pre-processing and conformance checking. For this example, we will work on the following example of event logs collected from an execution on Docker Swarm and the following state machine."]},{"cell_type":"code","execution_count":4,"id":"fcd215b4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcd215b4","outputId":"213fb328-989c-4fe6-f5bd-387c04e56281","executionInfo":{"status":"ok","timestamp":1668551190229,"user_tz":-60,"elapsed":279,"user":{"displayName":"Jeremy MECHOUCHE","userId":"11311834437755446740"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["             Timestamp     Source Resource Name         Event-Type     Metric Value\n","0  2022-11-15 00:00:03   Provider            UI     Service_Create   replicas     2\n","1  2022-11-15 00:00:04   Provider            UI   Container_Create          /     /\n","2  2022-11-15 00:00:05   Provider            UI    Container_Start          /     /\n","3  2022-11-15 00:00:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%\n","4  2022-11-15 00:01:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%\n","..                 ...        ...           ...                ...        ...   ...\n","73 2022-11-15 00:02:25  Ressource          Stor    Ressource_Usage  Cpu Usage   15%\n","74 2022-11-15 00:02:30  Ressource          Stor    Ressource_Usage  Cpu Usage   15%\n","75 2022-11-15 00:02:45   Provider          Stor     Service_Update   replicas     0\n","76 2022-11-15 00:02:46   Provider          Stor     Container_Stop          /     /\n","77 2022-11-15 00:02:47   Provider          Stor  Container_Destroy          /     /\n","\n","[78 rows x 6 columns]\n"]}],"source":["import pandas as pd\n","pd.set_option('display.width',1000)\n","\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/logs.csv')\n","df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n","\n","print(df)"]},{"cell_type":"markdown","id":"c1c76cbb","metadata":{"id":"c1c76cbb"},"source":["<h2>Pre-processing the collected logs</h2>\n","<h3>Annotation</h3>\n","\n","We begin the pre-processing by the annotation of this later collected event logs based on the domain Knowledge formulated as an ontology with protègè. This domain knowledge represents the correlation between event type and state-machine elements. "]},{"cell_type":"code","execution_count":5,"id":"8f353775","metadata":{"id":"8f353775","executionInfo":{"status":"ok","timestamp":1668551190645,"user_tz":-60,"elapsed":420,"user":{"displayName":"Jeremy MECHOUCHE","userId":"11311834437755446740"}}},"outputs":[],"source":["# Importing the owlready2 library and load the ontology \n","from owlready2 import *\n","onto = get_ontology(\"/content/drive/MyDrive/Colab Notebooks/eventLog.owl\").load()"]},{"cell_type":"markdown","id":"f42f2860","metadata":{"id":"f42f2860"},"source":["Then, we perform the high-level activity Identification using the ontology which returns the enriched Event logs with High-Level Activity. "]},{"cell_type":"code","execution_count":6,"id":"d91c06cb","metadata":{"id":"d91c06cb","executionInfo":{"status":"ok","timestamp":1668551190646,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jeremy MECHOUCHE","userId":"11311834437755446740"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1f1323d-d6fe-465e-dc55-0c6f2ac592cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["             Timestamp     Source Resource Name         Event-Type     Metric Value   smElement    lcStep\n","0  2022-11-15 00:00:03   Provider            UI     Service_Create   replicas     2       State     Start\n","1  2022-11-15 00:00:04   Provider            UI   Container_Create          /     /       State   Execute\n","2  2022-11-15 00:00:05   Provider            UI    Container_Start          /     /       State  Complete\n","3  2022-11-15 00:00:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%  Transition          \n","4  2022-11-15 00:01:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%  Transition          \n","..                 ...        ...           ...                ...        ...   ...         ...       ...\n","73 2022-11-15 00:02:25  Ressource          Stor    Ressource_Usage  Cpu Usage   15%  Transition          \n","74 2022-11-15 00:02:30  Ressource          Stor    Ressource_Usage  Cpu Usage   15%  Transition          \n","75 2022-11-15 00:02:45   Provider          Stor     Service_Update   replicas     0       State     Start\n","76 2022-11-15 00:02:46   Provider          Stor     Container_Stop          /     /       State  Complete\n","77 2022-11-15 00:02:47   Provider          Stor  Container_Destroy          /     /       State   Execute\n","\n","[78 rows x 8 columns]\n"]}],"source":["def get_ancestor(onto, value):\n","    \"\"\"\n","        Return the ancestor of a eventType to identify if it's related to an Event or a Transition\n","        Input Ontology 'owlready', value: name of classes\n","    \"\"\"\n","    ancestor = {}\n","    # Search the value in the ontology\n","    search = onto.search(iri = f\"*{value}\")[0]\n","    if search != None:\n","        # Identify ancestor which is not the root node or the class itself\n","        ancestor[0] = search.is_a[0]\n","        if ancestor[0].name != 'Transition':\n","            ancestor[1] = ancestor[0].is_a[0].name\n","            ancestor[0] = search.is_a[0].name\n","        else:\n","            ancestor[1] = ancestor[0].name\n","            ancestor[0] = ''\n","        return ancestor\n","    else:\n","        return 'N/A'\n","\n","# StateMachine Element\n","smElement = []\n","# Lifecycle Step\n","lcStep = []\n","for index, row in df.iterrows():\n","    anc = get_ancestor(onto, row['Event-Type'])\n","    smElement.append(anc[1])\n","    lcStep.append(anc[0])\n","\n","df['smElement'] = smElement\n","df['lcStep'] = lcStep\n","\n","print(df)"]},{"cell_type":"markdown","id":"269ce70a","metadata":{"id":"269ce70a"},"source":["<h3>Abstraction</h3>\n","Then, we perform the abstraction of Annotated logs in order to discover a state-machine representing the \"real\" observed behavior using defined patterns."]},{"cell_type":"code","execution_count":7,"id":"a4b659b4","metadata":{"id":"a4b659b4","executionInfo":{"status":"ok","timestamp":1668551190889,"user_tz":-60,"elapsed":247,"user":{"displayName":"Jeremy MECHOUCHE","userId":"11311834437755446740"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a6aa0f0-5790-4c7b-f7d6-51c6c10a0235"},"outputs":[{"output_type":"stream","name":"stdout","text":["Discovered State-Machines\n","{'Auth': {'States': [(S_disc_1, isInitial, {'replicas': '2'}), (S_disc_2, isNormal, {'replicas': '4'}), (S_disc_3, isNormal, {'replicas': '6'}), (S_disc_4, isFinal, {'replicas': '8'})], 'Transitions': [{'lt': 'T_disc_1', 'ss': 'S_disc_1', 'st': 'S_disc_2', 'E': '', 'A': '+2'}, {'lt': 'T_disc_2', 'ss': 'S_disc_2', 'st': 'S_disc_3', 'E': '', 'A': '+2'}, {'lt': 'T_disc_3', 'ss': 'S_disc_3', 'st': 'S_disc_4', 'E': '', 'A': '+2'}]}, 'Stor': {'States': [(S_disc_1, isInitial, {'replicas': '2'}), (S_disc_2, isNormal, {'replicas': '4'}), (S_disc_3, isNormal, {'replicas': '6'}), (S_disc_4, isNormal, {'replicas': '8'}), (S_disc_5, isFinal, {'replicas': '12'})], 'Transitions': [{'lt': 'T_disc_1', 'ss': 'S_disc_1', 'st': 'S_disc_2', 'E': '', 'A': '+2'}, {'lt': 'T_disc_2', 'ss': 'S_disc_2', 'st': 'S_disc_3', 'E': '', 'A': '+2'}, {'lt': 'T_disc_3', 'ss': 'S_disc_3', 'st': 'S_disc_4', 'E': '', 'A': '+2'}, {'lt': 'T_disc_4', 'ss': 'S_disc_4', 'st': 'S_disc_5', 'E': '', 'A': '-4'}]}, 'UI': {'States': [(S_disc_1, isInitial, {'replicas': '2'}), (S_disc_2, isNormal, {'replicas': '4'}), (S_disc_3, isFinal, {'replicas': '6'})], 'Transitions': [{'lt': 'T_disc_1', 'ss': 'S_disc_1', 'st': 'S_disc_2', 'E': '', 'A': '+2'}, {'lt': 'T_disc_2', 'ss': 'S_disc_2', 'st': 'S_disc_3', 'E': '', 'A': '+2'}]}}\n"]}],"source":["from numpy import empty\n","\n","Discovered_SM = {}\n","#Patterns implementation\n","## State Abstraction\n","df_group = df.groupby(['Resource Name'])\n","for Resource in df_group.groups:\n","    Discovered_SM[Resource] = {}\n","    Discovered_SM[Resource]['States'] = []\n","    Discovered_SM[Resource]['Transitions'] = []\n","    df_resource = df[df_group.groups[Resource][0]:df_group.groups[Resource][-1]]\n","    state_pattern = (df_resource['lcStep'] == \"Start\") & (df_resource['lcStep'].shift(-1) == 'Execute') & (df_resource['lcStep'].shift(-2) == 'Complete')\n","    indice_state = df_resource.index[state_pattern]\n","    if indice_state is not empty:\n","        for i in indice_state:\n","            Discovered_SM[Resource]['States'].append(StateMachine.state(name = 'S_disc_'+str((len(Discovered_SM[Resource]['States'])+1)), type = 'notDefined',Resourcerequirements = {'replicas': df['Value'][i]}))\n","    else:\n","        print(\"No state has been discovered\")\n","\n","## State-Type Abstraction\n","for SM in Discovered_SM:\n","    max = len(Discovered_SM[SM]['States'])\n","    Discovered_SM[SM]['States'][0].type = 'isInitial'\n","    Discovered_SM[SM]['States'][max-1].type = 'isFinal'\n","    for i in range(1,(max-1)):\n","        Discovered_SM[SM]['States'][i].type = 'isNormal'\n","\n","## Reconfiguration Actions Abstraction\n","for SM in Discovered_SM:\n","    nb_states = len(Discovered_SM[SM]['States'])\n","    for state in range(nb_states - 1):\n","        if Discovered_SM[SM]['States'][state].Resourcerequirements['replicas'] > Discovered_SM[SM]['States'][state+1].Resourcerequirements['replicas'] :\n","            value_action = '-' + str(int(Discovered_SM[SM]['States'][state+1].Resourcerequirements['replicas']) - int(Discovered_SM[SM]['States'][state].Resourcerequirements['replicas']))\n","        else:\n","            value_action = '+' + str(int(Discovered_SM[SM]['States'][state+1].Resourcerequirements['replicas']) - int(Discovered_SM[SM]['States'][state].Resourcerequirements['replicas']))\n","        Discovered_SM[SM]['Transitions'].append({'lt':'T_disc_'+str((len(Discovered_SM[SM]['Transitions'])+1)),'ss': Discovered_SM[SM]['States'][state].name,'st': Discovered_SM[SM]['States'][state+1].name,'E':'','A':value_action})\n","\n","print(\"Discovered State-Machines\")\n","print(Discovered_SM)"]},{"cell_type":"markdown","id":"d7d01aff","metadata":{"id":"d7d01aff"},"source":["<h2>Checker</h2>\n","In this last step, we implement the checker component. We construct the search space as defined in the paper. "]},{"cell_type":"code","execution_count":null,"id":"cdb4bf50","metadata":{"id":"cdb4bf50"},"outputs":[],"source":["import pm4py\n","import networkx as nx\n","\n","# For each discovered State-Machine\n","for SM in Discovered_SM:\n","    SS = nx.Graph()\n","    for eltx, elty in zip(Discovered_SM[SM]['States'], SM_defined.states):\n","        if eltx.Resourcerequirements == elty.Resourcerequirements:\n","            SS.add_node(str([eltx.name,elty.name]), weight=1)\n","        else :\n","            SS.add_node(str([eltx.name,'>>']), weight=5)\n","            SS.add_node(str(['>>',elty.name]), weight=5)\n","    print(SS)"]},{"cell_type":"markdown","id":"fd753b68","metadata":{"id":"fd753b68"},"source":["From this space, we search the optimal alignment using an A* algorithm."]},{"cell_type":"code","execution_count":null,"id":"cb5e739a","metadata":{"id":"cb5e739a"},"outputs":[],"source":["y_optimal = nx.shortest_path(SS, 'isInitial', 'isFinal')"]},{"cell_type":"markdown","id":"e1acb82a","metadata":{"id":"e1acb82a"},"source":["Finally, we compute the fitness value of the identified alignment and return the report with the alignment."]},{"cell_type":"code","execution_count":null,"id":"8d5f583f","metadata":{"id":"8d5f583f","executionInfo":{"status":"aborted","timestamp":1668551190893,"user_tz":-60,"elapsed":13,"user":{"displayName":"Jeremy MECHOUCHE","userId":"11311834437755446740"}}},"outputs":[],"source":["y_worst_sum = sum(y_worst)\n","y_optimal_sum = sum(y_optimal)\n","fitnessValue = 1 - y_optimal/y_worst\n","\n","print(\"Report : \")\n","print(f\"Y_Optimal : {y_optimal}\")\n","print(f\"FitnessValue : {fitnessValue}\")"]}],"metadata":{"colab":{"provenance":[]},"interpreter":{"hash":"554a963c2ab7e9dbc972b0841a9795b35c5d20e07f7df3c22746535bc7388380"},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}