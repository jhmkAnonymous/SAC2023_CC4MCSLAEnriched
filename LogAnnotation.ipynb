{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FOvNMxQdjQKi",
      "metadata": {
        "id": "FOvNMxQdjQKi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22701961",
      "metadata": {
        "id": "22701961"
      },
      "outputs": [],
      "source": [
        "!pip install pm4py owlready2 pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e2e563",
      "metadata": {
        "id": "35e2e563"
      },
      "source": [
        "<h1>Experiments Leveraging Conformance Checking Techniques for Multi-Cloud SLA Compliance </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6e2315",
      "metadata": {
        "id": "7e6e2315"
      },
      "source": [
        "The main objective of this notebook is to present the implementation part of the paper submited to SAC 2023. This implementation is decomposed in two steps: Log pre-processing and conformance checking. For this example, we will work on the following example of event logs collected from an execution on Docker Swarm and the following state machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcd215b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcd215b4",
        "outputId": "c734f74c-7741-4595-a365-2774e3d66221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Timestamp     Source Resource Name         Event-Type     Metric Value\n",
            "0  2022-10-30 00:00:03   Provider            UI     Service_Create   replicas     2\n",
            "1  2022-10-30 00:00:03   Provider            UI   Container_Create          /     /\n",
            "2  2022-10-30 00:00:03   Provider            UI    Container_Start          /     /\n",
            "3  2022-10-30 00:00:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%\n",
            "4  2022-10-30 00:01:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%\n",
            "..                 ...        ...           ...                ...        ...   ...\n",
            "73 2022-10-30 00:03:15  Ressource          Stor    Ressource_Usage  Cpu Usage   15%\n",
            "74 2022-10-30 00:03:30  Ressource          Stor    Ressource_Usage  Cpu Usage   15%\n",
            "75 2022-10-30 00:03:45  Provider           Stor     Service_Update   replicas     0\n",
            "76 2022-10-30 00:03:45  Provider           Stor     Container_Stop          /     /\n",
            "77 2022-10-30 00:03:45  Provider           Stor  Container_Destroy          /     /\n",
            "\n",
            "[78 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width',1000)\n",
        "\n",
        "df = pd.read_csv('logs.csv')\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c76cbb",
      "metadata": {
        "id": "c1c76cbb"
      },
      "source": [
        "<h2>Pre-processing the collected logs</h2>\n",
        "<h3>Annotation</h3>\n",
        "\n",
        "We begin the pre-processing by the annotation of this later collected event logs based on the domain Knowledge formulated as an ontology with protègè. This domain knowledge represents the correlation between event type and state-machine elements. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f353775",
      "metadata": {
        "id": "8f353775"
      },
      "outputs": [],
      "source": [
        "# Importing the owlready2 library and load the ontology \n",
        "from owlready2 import *\n",
        "onto = get_ontology(\"eventLog.owl\").load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42f2860",
      "metadata": {
        "id": "f42f2860"
      },
      "source": [
        "Then, we perform the high-level activity Identification using the ontology which returns the enriched Event logs with High-Level Activity. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91c06cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d91c06cb",
        "outputId": "67e11709-07c4-4732-bc5c-dd5953d9ff4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Timestamp     Source Resource Name         Event-Type     Metric Value   smElement    lcStep\n",
            "0  2022-10-30 00:00:03   Provider            UI     Service_Create   replicas     2       State     Start\n",
            "1  2022-10-30 00:00:03   Provider            UI   Container_Create          /     /       State   Execute\n",
            "2  2022-10-30 00:00:03   Provider            UI    Container_Start          /     /       State  Complete\n",
            "3  2022-10-30 00:00:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%  Transition          \n",
            "4  2022-10-30 00:01:05  Ressource            UI    Ressource_Usage  Cpu Usage   15%  Transition          \n",
            "..                 ...        ...           ...                ...        ...   ...         ...       ...\n",
            "73 2022-10-30 00:03:15  Ressource          Stor    Ressource_Usage  Cpu Usage   15%  Transition          \n",
            "74 2022-10-30 00:03:30  Ressource          Stor    Ressource_Usage  Cpu Usage   15%  Transition          \n",
            "75 2022-10-30 00:03:45  Provider           Stor     Service_Update   replicas     0       State     Start\n",
            "76 2022-10-30 00:03:45  Provider           Stor     Container_Stop          /     /       State  Complete\n",
            "77 2022-10-30 00:03:45  Provider           Stor  Container_Destroy          /     /       State   Execute\n",
            "\n",
            "[78 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "def get_ancestor(onto, value):\n",
        "    \"\"\"\n",
        "        Return the ancestor of a eventType to identify if it's related to an Event or a Transition\n",
        "        Input Ontology 'owlready', value: name of classes\n",
        "    \"\"\"\n",
        "    ancestor = {}\n",
        "    # Search the value in the ontology\n",
        "    search = onto.search(iri = f\"*{value}\")[0]\n",
        "    if search != None:\n",
        "        # Identify ancestor which is not the root node or the class itself\n",
        "        ancestor[0] = search.is_a[0]\n",
        "        if ancestor[0].name != 'Transition':\n",
        "            ancestor[1] = ancestor[0].is_a[0].name\n",
        "            ancestor[0] = search.is_a[0].name\n",
        "        else:\n",
        "            ancestor[1] = ancestor[0].name\n",
        "            ancestor[0] = ''\n",
        "        return ancestor\n",
        "    else:\n",
        "        return 'N/A'\n",
        "\n",
        "# StateMachine Element\n",
        "smElement = []\n",
        "# Lifecycle Step\n",
        "lcStep = []\n",
        "for index, row in df.iterrows():\n",
        "    anc = get_ancestor(onto, row['Event-Type'])\n",
        "    smElement.append(anc[1])\n",
        "    lcStep.append(anc[0])\n",
        "\n",
        "df['smElement'] = smElement\n",
        "df['lcStep'] = lcStep\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "269ce70a",
      "metadata": {
        "id": "269ce70a"
      },
      "source": [
        "<h3>Abstraction</h3>\n",
        "Then, we perform the abstraction of Annotated logs in order to discover a state-machine representing the \"real\" observed behavior using defined patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b659b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "a4b659b4",
        "outputId": "62cf1b0d-e8f9-40fd-d635-e1d0d3defeda"
      },
      "outputs": [],
      "source": [
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format= '%H:%M:%S')\n",
        "a = df.loc[df['smElement'] =='State']\n",
        "a = a.groupby(['smElement'])\n",
        "\n",
        "print(a)\n",
        "\n",
        "df['Potential_State'] = 'State'+(a['Timestamp'].diff()/pd.Timedelta(seconds=15)).gt(1).cumsum().add(1).astype(str)\n",
        "\n",
        "SMdisc = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d01aff",
      "metadata": {
        "id": "d7d01aff"
      },
      "source": [
        "<h2>Checker</h2>\n",
        "In this last step, we implement the checker component. We construct the search space as defined in the paper. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdb4bf50",
      "metadata": {
        "id": "cdb4bf50"
      },
      "outputs": [],
      "source": [
        "import pm4py\n",
        "import networkx as nx\n",
        "SS = nx.Graph()\n",
        "\n",
        "for eltx in SMdisc:\n",
        "    if eltx == elty:\n",
        "        SS.add_node(1)\n",
        "    else :\n",
        "        SS.add_node(1)\n",
        "        SS.add_node(2)\n",
        "    SMdef.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd753b68",
      "metadata": {},
      "source": [
        "From this space, we search the optimal alignment using an A* algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5e739a",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_optimal = nx.shortest_path(SS, start, end)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1acb82a",
      "metadata": {},
      "source": [
        "Finally, we compute the fitness value of the identified alignment and return the report with the alignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d5f583f",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_worst_sum = sum(y_worst)\n",
        "y_optimal_sum = sum(y_optimal)\n",
        "fitness Value = 1 - y_optimal/y_worst"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "interpreter": {
      "hash": "554a963c2ab7e9dbc972b0841a9795b35c5d20e07f7df3c22746535bc7388380"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
